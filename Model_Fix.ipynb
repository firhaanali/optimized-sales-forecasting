{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMZUfWtGFD9kRAwPnGKSd5y",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/firhaanali/optimized-sales-forecasting/blob/main/Model_Fix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install Package"
      ],
      "metadata": {
        "id": "O6VSTBuex21O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize\n",
        "!pip install requests\n",
        "!pip install optuna"
      ],
      "metadata": {
        "id": "HqMK3WKinX3K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import Library"
      ],
      "metadata": {
        "id": "PiI4Ggtjx8M-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import warnings\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import requests\n",
        "import xgboost as xgb\n",
        "import time\n",
        "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Mount Google Drive and load dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "file_path = '/content/drive/My Drive/Dataset/dataset_merged.xlsx'\n",
        "df = pd.read_excel(file_path)\n",
        "print(f\"Dataset loaded with {df.shape[0]} rows and {df.shape[1]} columns.\")"
      ],
      "metadata": {
        "id": "-uEFJr9VmvZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Cleaning\n"
      ],
      "metadata": {
        "id": "OrJvUDkFyERq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standarisasi nama kolom\n",
        "original_columns = df.columns.tolist()\n",
        "df.columns = df.columns.str.strip().str.replace(\" \", \"_\", regex=False)\n",
        "\n",
        "# Check missing values\n",
        "missing_values = df.isnull().sum()\n",
        "missing_values = missing_values[missing_values > 0]\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.barh(range(len(df.columns)), [1]*len(df.columns))  # Membuat semua batang dengan tinggi 1\n",
        "plt.yticks(range(len(df.columns)), df.columns)\n",
        "plt.title('Daftar Fitur dalam Dataset')\n",
        "plt.xlabel('Jumlah')\n",
        "plt.ylabel('Fitur (Kolom)')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lU6iwb2HnQiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning\n",
        "df['Size'] = df['Size'].fillna('All_Size').astype(str).str.replace(\"Ld \", \"\", case=False).str.strip()\n",
        "df['Payment_platform_discount'] = pd.to_numeric(df['Payment_platform_discount'], errors='coerce').fillna(0)\n",
        "df['Handling_Fee'] = pd.to_numeric(df['Handling_Fee'], errors='coerce').fillna(0)"
      ],
      "metadata": {
        "id": "zYEbDNcfJ1WO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "gwyQ01CWyKbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time Extraction"
      ],
      "metadata": {
        "id": "9Jp4ed35yNmq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_columns = df.columns.tolist()\n",
        "\n",
        "# Feature Engineering - Time Features\n",
        "if 'Created_Time' in df.columns:\n",
        "    df['Created_Time'] = pd.to_datetime(df['Created_Time'], errors='coerce', dayfirst=True)\n",
        "    df.dropna(subset=['Created_Time'], inplace=True)\n",
        "\n",
        "# Extract basic time features\n",
        "df['year'] = df['Created_Time'].dt.year\n",
        "df['month'] = df['Created_Time'].dt.month\n",
        "df['day'] = df['Created_Time'].dt.day\n",
        "df['hour'] = df['Created_Time'].dt.hour\n",
        "df['minute'] = df['Created_Time'].dt.minute\n",
        "df['second'] = df['Created_Time'].dt.second\n",
        "df['day_of_week'] = df['Created_Time'].dt.dayofweek\n",
        "df['day_of_year'] = df['Created_Time'].dt.dayofyear\n",
        "df['quarter'] = df['Created_Time'].dt.quarter\n",
        "df['week_of_year'] = df['Created_Time'].dt.isocalendar().week\n",
        "\n",
        "# Cyclical transformations\n",
        "df['month_sin'] = np.sin(2 * np.pi * df['month'] / 12)\n",
        "df['month_cos'] = np.cos(2 * np.pi * df['month'] / 12)\n",
        "df['day_of_week_sin'] = np.sin(2 * np.pi * df['day_of_week'] / 7)\n",
        "df['day_of_week_cos'] = np.cos(2 * np.pi * df['day_of_week'] / 7)\n",
        "df['day_of_year_sin'] = np.sin(2 * np.pi * df['day_of_year'] / 365)\n",
        "df['day_of_year_cos'] = np.cos(2 * np.pi * df['day_of_year'] / 365)\n",
        "df['hour_sin'] = np.sin(2 * np.pi * df['hour'] / 24)\n",
        "df['hour_cos'] = np.cos(2 * np.pi * df['hour'] / 24)\n",
        "\n",
        "# Calendar/event features\n",
        "df['is_payday'] = df['day'].isin([25, 26, 27, 28, 29, 30, 31, 1, 2]).astype(int)\n",
        "df['date'] = df['Created_Time'].dt.date\n",
        "df['year_month'] = df['Created_Time'].dt.strftime('%Y-%m')\n",
        "df['year_week'] = df['year'].astype(str) + '-' + df['week_of_year'].astype(str).str.zfill(2)\n",
        "\n",
        "# Flash sale features\n",
        "flash_dates = [f\"{str(i).zfill(2)}-{str(i).zfill(2)}\" for i in range(1, 13)]\n",
        "df['flash_date_str'] = df['month'].astype(str).str.zfill(2) + '-' + df['day'].astype(str).str.zfill(2)\n",
        "df['is_flash_sale'] = df['flash_date_str'].isin(flash_dates).astype(int)\n",
        "\n",
        "# National holidays\n",
        "years = [2022, 2023, 2024, 2025]\n",
        "holiday_dates = []\n",
        "\n",
        "for year in years:\n",
        "    url = f\"https://date.nager.at/api/v3/PublicHolidays/{year}/ID\"\n",
        "    response = requests.get(url)\n",
        "    if response.status_code == 200:\n",
        "        data = response.json()\n",
        "        for holiday in data:\n",
        "            holiday_dates.append(holiday['date'])\n",
        "\n",
        "libur_nasional = pd.to_datetime(holiday_dates)\n",
        "df['is_holiday'] = df['Created_Time'].dt.date.isin(libur_nasional.date).astype(int)\n",
        "\n",
        "# Additional flags\n",
        "df['is_weekend'] = (df['day_of_week'] >= 5).astype(int)\n",
        "df['is_business_hour'] = (((df['hour'] >= 8) & (df['hour'] <= 17)) & (df['day_of_week'] < 5)).astype(int)\n",
        "df['is_month_start'] = (df['day'] <= 7).astype(int)\n",
        "df['is_month_end'] = (df['day'] >= 24).astype(int)\n",
        "\n",
        "after_time_columns = df.columns.tolist()\n",
        "added_time_features = [col for col in after_time_columns if col not in original_columns]\n",
        "\n",
        "# Visualisasi\n",
        "if added_time_features:\n",
        "    fig, ax = plt.subplots(figsize=(8, len(added_time_features) * 0.3))\n",
        "    bars = ax.barh(added_time_features, [1]*len(added_time_features), edgecolor='black')\n",
        "\n",
        "    for bar in bars:\n",
        "        ax.text(1.05, bar.get_y() + bar.get_height()/2, '1', va='center', fontsize=10)\n",
        "\n",
        "    ax.set_title('Fitur Baru dari Feature Engineering Waktu', fontsize=14, pad=10)\n",
        "    ax.set_xlabel('Fitur Baru')\n",
        "    ax.set_xlim(0, 1.2)\n",
        "    ax.set_xticks([])\n",
        "    ax.invert_yaxis()\n",
        "    plt.subplots_adjust(left=0.25, right=0.95, top=0.95, bottom=0.05)\n",
        "    plt.grid(False)\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "fMV1WorznOA6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time - Series"
      ],
      "metadata": {
        "id": "Ed10u_bUyQzQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Engineering - Time Series Features\n",
        "df = df.sort_values('Created_Time')\n",
        "df['date'] = df['Created_Time'].dt.date\n",
        "\n",
        "if 'Product_Name' in df.columns and 'Created_Time' in df.columns:\n",
        "    # Daily sales aggregation per product\n",
        "    daily_sales = df.groupby(['Product_Name', 'date'])['Quantity'].sum().reset_index()\n",
        "    daily_sales = daily_sales.sort_values(['Product_Name', 'date'])\n",
        "\n",
        "    # Create lag features\n",
        "    for lag in [1, 7, 14, 30]:\n",
        "        daily_sales[f'lag_{lag}_days'] = daily_sales.groupby('Product_Name')['Quantity'].shift(lag)\n",
        "\n",
        "    # Moving Averages & Rolling Sum\n",
        "    for window in [7, 14, 30]:\n",
        "        daily_sales[f'moving_avg_{window}'] = daily_sales.groupby('Product_Name')['Quantity'].transform(\n",
        "            lambda x: x.rolling(window=window, min_periods=1).mean()\n",
        "        )\n",
        "        daily_sales[f'rolling_sum_{window}'] = daily_sales.groupby('Product_Name')['Quantity'].transform(\n",
        "            lambda x: x.rolling(window=window, min_periods=1).sum()\n",
        "        )\n",
        "\n",
        "    # Merge time series features to main dataframe\n",
        "    df = pd.merge(\n",
        "        df,\n",
        "        daily_sales[['Product_Name', 'date'] +\n",
        "                    [f'lag_{lag}_days' for lag in [1, 7, 14, 30]] +\n",
        "                    [f'moving_avg_{window}' for window in [7, 14, 30]] +\n",
        "                    [f'rolling_sum_{window}' for window in [7, 14, 30]]],\n",
        "        on=['Product_Name', 'date'],\n",
        "        how='left'\n",
        "    )\n",
        "\n",
        "    # Volatility features\n",
        "    df['demand_std_7days'] = daily_sales.groupby('Product_Name')['Quantity'].transform(\n",
        "        lambda x: x.rolling(window=7, min_periods=1).std()\n",
        "    )\n",
        "\n",
        "    # Sales trends and ratios\n",
        "    df['sales_trend'] = (df['lag_7_days'] - df['lag_14_days']) / (df['lag_14_days'] + 1) * 100\n",
        "    df['sales_ratio_to_avg'] = df['Quantity'] / (df['moving_avg_30'] + 1)\n",
        "\n",
        "# Flash sale features\n",
        "df['flash_sale_yesterday'] = df.groupby('Product_Name')['is_flash_sale'].shift(1).fillna(0)\n",
        "df['days_since_last_flash'] = (\n",
        "    df[::-1].groupby('Product_Name')['is_flash_sale']\n",
        "    .apply(lambda x: x.cumsum().shift(-1).fillna(0))\n",
        "    .reset_index(level=0, drop=True)[::-1]\n",
        ")\n",
        "\n",
        "# Holiday and payday features\n",
        "df['holiday_yesterday'] = df['is_holiday'].shift(1).fillna(0)\n",
        "df['payday_yesterday'] = df['is_payday'].shift(1).fillna(0)\n",
        "\n",
        "# Additional time features\n",
        "df['week_of_month'] = pd.to_datetime(df['date']).dt.day.apply(lambda d: (d - 1) // 7 + 1)\n",
        "\n",
        "# Monthly seasonal index\n",
        "if 'month' in df.columns:\n",
        "    # Calculate monthly average per product\n",
        "    monthly_avg = df.groupby(['Product_Name', 'month'])['Quantity'].mean().reset_index()\n",
        "\n",
        "    # Calculate overall average per product\n",
        "    product_avg = monthly_avg.groupby('Product_Name')['Quantity'].mean().reset_index()\n",
        "\n",
        "    # Join to calculate seasonal index\n",
        "    monthly_avg = pd.merge(monthly_avg, product_avg, on='Product_Name', suffixes=('_month', '_product'))\n",
        "    monthly_avg['seasonal_index'] = monthly_avg['Quantity_month'] / monthly_avg['Quantity_product']\n",
        "\n",
        "    # Join seasonal index to main dataframe\n",
        "    df = pd.merge(df, monthly_avg[['Product_Name', 'month', 'seasonal_index']],\n",
        "                  on=['Product_Name', 'month'], how='left')\n",
        "\n",
        "# Fill NaN values for all time series features\n",
        "ts_columns = [col for col in df.columns if 'lag_' in col or 'moving_avg_' in col or\n",
        "              'trend' in col or 'ratio' in col or 'seasonal' in col or\n",
        "              'std' in col or 'flash' in col or 'holiday_yesterday' in col or\n",
        "              'payday_yesterday' in col]\n",
        "for col in ts_columns:\n",
        "    if col in df.columns:\n",
        "        df[col] = df[col].fillna(0)\n",
        "\n",
        "# Drop and Save\n",
        "created_times = df['Created_Time'].copy()\n",
        "product_names = df['Product_Name'].copy()\n",
        "variations = df['Variation'].copy() if 'Variation' in df.columns else None\n",
        "sizes = df['Size'].copy() if 'Size' in df.columns else None\n",
        "\n",
        "# Drop non-feature columns\n",
        "df.drop(columns=['Created_Time', 'date', 'year_month', 'year_week'], inplace=True, errors='ignore')\n",
        "df.drop(columns=['Product_Name', 'Variation', 'Size'], inplace=True, errors='ignore')\n",
        "\n",
        "after_ts_columns = df.columns.tolist()\n",
        "added_ts_features = [col for col in after_ts_columns if col not in after_time_columns]\n",
        "\n",
        "# Visualisasi\n",
        "if added_ts_features:\n",
        "    fig, ax = plt.subplots(figsize=(8, len(added_ts_features) * 0.3))\n",
        "    bars = ax.barh(added_ts_features, [1]*len(added_ts_features), edgecolor='black')\n",
        "\n",
        "    for bar in bars:\n",
        "        ax.text(1.05, bar.get_y() + bar.get_height()/2, '1', va='center', fontsize=10)\n",
        "\n",
        "    ax.set_title('Fitur Baru dari Feature Engineering Time Series', fontsize=14, pad=10)\n",
        "    ax.set_xlabel('Fitur Baru')\n",
        "    ax.set_xlim(0, 1.2)\n",
        "    ax.set_xticks([])\n",
        "    ax.invert_yaxis()\n",
        "    plt.subplots_adjust(left=0.25, right=0.95, top=0.95, bottom=0.05)\n",
        "    plt.grid(False)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "u92UkqOQnKa5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Split"
      ],
      "metadata": {
        "id": "fpke6WR4yZEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Validation-Test Split\n",
        "target_column = 'Quantity'\n",
        "columns_to_drop = ['year_month', 'date', 'flash_date_str']\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(columns=[target_column] + [col for col in columns_to_drop if col in df.columns])\n",
        "y = np.log1p(df[target_column])  # Log transform for better model performance\n",
        "\n",
        "# Time-based split\n",
        "train_size = int(0.8 * len(df))\n",
        "valid_size = int(0.1 * len(df))\n",
        "\n",
        "X_train = X.iloc[:train_size]\n",
        "y_train = y.iloc[:train_size]\n",
        "X_valid = X.iloc[train_size:train_size+valid_size]\n",
        "y_valid = y.iloc[train_size:train_size+valid_size]\n",
        "X_test = X.iloc[train_size+valid_size:]\n",
        "y_test = y.iloc[train_size+valid_size:]\n",
        "\n",
        "# Hitung jumlah sampel\n",
        "counts = [len(X_train), len(X_valid), len(X_test)]\n",
        "labels = ['Training', 'Validation', 'Testing']\n",
        "percentages = [count / (len(X_train) + len(X_valid) + len(X_test)) * 100 for count in counts]\n",
        "\n",
        "# Visualisasi\n",
        "print(\"Distribusi Jumlah Data:\")\n",
        "print(f\"Training\\t: {counts[0]} sampel ({percentages[0]:.1f}%)\")\n",
        "print(f\"Validation\\t: {counts[1]} sampel ({percentages[1]:.1f}%)\")\n",
        "print(f\"Testing\\t\\t: {counts[2]} sampel ({percentages[2]:.1f}%)\")\n",
        "print(f\"Total\\t\\t: {sum(counts)} sampel (100%)\")\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.barplot(x=labels, y=counts, hue=labels, palette='Set2', legend=False)\n",
        "\n",
        "for i, (count, pct) in enumerate(zip(counts, percentages)):\n",
        "    plt.text(i, count + 5, f'{pct:.1f}%', ha='center', va='bottom', fontsize=12)\n",
        "\n",
        "plt.title('Distribusi Data: Train / Validation / Test')\n",
        "plt.ylabel('Jumlah Sampel')\n",
        "plt.grid(True, axis='y', linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3mPDgkQ6nE6C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Selection\n",
        "feature_selector = xgb.XGBRegressor(random_state=42)\n",
        "feature_selector.fit(X_train, y_train)\n",
        "\n",
        "feature_importance = pd.DataFrame({\n",
        "    'Feature': X_train.columns,\n",
        "    'Importance': feature_selector.feature_importances_\n",
        "})\n",
        "feature_importance = feature_importance.sort_values(by='Importance', ascending=False)\n",
        "\n",
        "importance_mean = feature_importance['Importance'].mean()\n",
        "print(f\"Mean Importance Score: {importance_mean:.4f}\")\n",
        "\n",
        "selector = SelectFromModel(feature_selector, threshold=importance_mean, prefit=True)\n",
        "selected_features = X_train.columns[selector.get_support()]\n",
        "print(f\"Selected {len(selected_features)} features from total {X_train.shape[1]} initial features.\")\n",
        "\n",
        "# Use selected features for all data subsets\n",
        "X_train = X_train[selected_features]\n",
        "X_valid = X_valid[selected_features]\n",
        "X_test = X_test[selected_features]\n",
        "\n",
        "# Filter hanya fitur yang dipilih\n",
        "selected_feature_importance = feature_importance[feature_importance['Feature'].isin(selected_features)]\n",
        "\n",
        "# Visualisasi\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.barplot(\n",
        "    data=selected_feature_importance,\n",
        "    x='Importance',\n",
        "    y='Feature',\n",
        "    hue='Feature',\n",
        "    dodge=False,\n",
        "    palette='viridis',\n",
        "    legend=False\n",
        ")\n",
        "\n",
        "# Tambahkan nilai pada setiap batang\n",
        "for i, val in enumerate(selected_feature_importance['Importance']):\n",
        "    plt.text(val + 0.005, i, f\"{val:.3f}\", va='center')\n",
        "\n",
        "plt.axvline(importance_mean, color='red', linestyle='--', label='Mean Threshold')\n",
        "plt.title('Feature Importance dari Fitur yang Dipilih', fontsize=14)\n",
        "plt.xlabel('Importance Score', fontsize=12)\n",
        "plt.ylabel('Fitur', fontsize=12)\n",
        "plt.grid(True, axis='x', linestyle='--', alpha=0.6)\n",
        "plt.tight_layout()\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(f\"‚úÖ Terpilih {len(selected_features)} fitur dari total {X_train.shape[1]} fitur awal.\")"
      ],
      "metadata": {
        "id": "CrW52Gkayd_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Baseline Model\n",
        "model_baseline = xgb.XGBRegressor(random_state=42, eval_metric=[\"rmse\"])\n",
        "\n",
        "# Create DMatrix for training and validation\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
        "\n",
        "# Set basic model parameters\n",
        "params = {\n",
        "    'objective': 'reg:squarederror',\n",
        "    'eval_metric': 'rmse',\n",
        "    'random_state': 42\n",
        "}\n",
        "\n",
        "# Prepare eval_set and evaluation results dictionary\n",
        "evals = [(dtrain, 'train'), (dvalid, 'valid')]\n",
        "evals_result = {}\n",
        "\n",
        "# Train with early stopping\n",
        "model = xgb.train(\n",
        "    params=params,\n",
        "    dtrain=dtrain,\n",
        "    num_boost_round=1000,\n",
        "    evals=evals,\n",
        "    early_stopping_rounds=20,\n",
        "    evals_result=evals_result,\n",
        "    verbose_eval=False\n",
        ")\n",
        "\n",
        "# 5. Ambil RMSE dan konversi ke MSE\n",
        "rmse_train = np.array(evals_result['train']['rmse'])\n",
        "rmse_valid = np.array(evals_result['valid']['rmse'])\n",
        "mse_train = rmse_train ** 2\n",
        "mse_valid = rmse_valid ** 2\n",
        "\n",
        "# 6. Visualisasi Learning Curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(mse_train, label='Train MSE')\n",
        "plt.plot(mse_valid, label='Validation MSE')\n",
        "plt.axvline(x=model.best_iteration, color='r', linestyle='--', label='Best Iteration')\n",
        "plt.title(\"XGBoost Baseline - MSE Learning Curve\")\n",
        "plt.xlabel(\"Boosting Rounds\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2iobRiRtm-x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameter Tuning with Bayesian Optimization\n",
        "param_bayes = {\n",
        "    'max_depth': Integer(3, 10),\n",
        "    'learning_rate': Real(0.001, 1, prior='log-uniform'),\n",
        "    'n_estimators': Integer(50, 500),\n",
        "    'subsample': Real(0.1, 1.0, prior='uniform'),\n",
        "    'colsample_bytree': Real(0.1, 1.0, prior='uniform'),\n",
        "}\n",
        "\n",
        "model_xgb = xgb.XGBRegressor(\n",
        "    objective='reg:squarederror',\n",
        "    random_state=42,\n",
        "    verbosity=0\n",
        ")\n",
        "\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "bayes_search = BayesSearchCV(\n",
        "    estimator=model_xgb,\n",
        "    search_spaces=param_bayes,\n",
        "    n_iter=100,\n",
        "    cv=tscv,\n",
        "    scoring='neg_mean_squared_error',\n",
        "    n_jobs=1,\n",
        "    verbose=3,\n",
        "    random_state=42,\n",
        "    return_train_score=True\n",
        ")\n",
        "\n",
        "print(\"Starting parameter search with Bayesian Optimization...\")\n",
        "start_bayes = time.time()\n",
        "bayes_search.fit(X_train, y_train)\n",
        "end_bayes = time.time()\n",
        "print(f\"Completed in {(end_bayes - start_bayes) / 60:.2f} minutes.\")\n",
        "\n",
        "# Save best model from Bayesian Optimization\n",
        "model_optimized = bayes_search.best_estimator_\n",
        "\n",
        "# Get best parameters\n",
        "best_params = bayes_search.best_params_\n",
        "print(\"\\nOptimal Parameters:\")\n",
        "for param, value in best_params.items():\n",
        "    print(f\"{param}: {value}\")\n",
        "\n",
        "# Set parameters from Bayesian Optimization\n",
        "params = bayes_search.best_params_\n",
        "params.update({\n",
        "    'objective': 'reg:squarederror',\n",
        "    'eval_metric': 'rmse',\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "})\n",
        "\n",
        "# Prepare eval list and results dictionary\n",
        "evals = [(dtrain, 'train'), (dvalid, 'valid')]\n",
        "evals_result = {}\n",
        "\n",
        "# Train model with early stopping\n",
        "model = xgb.train(\n",
        "    params=params,\n",
        "    dtrain=dtrain,\n",
        "    num_boost_round=1000,\n",
        "    evals=evals,\n",
        "    early_stopping_rounds=20,\n",
        "    evals_result=evals_result,\n",
        "    verbose_eval=False\n",
        ")"
      ],
      "metadata": {
        "id": "n7q0qW-Um7SL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gudq8XzuFIGn"
      },
      "outputs": [],
      "source": [
        "# Siapkan DMatrix\n",
        "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
        "dvalid = xgb.DMatrix(X_valid, label=y_valid)\n",
        "\n",
        "# Parameter hasil Bayesian Optimization\n",
        "params = bayes_search.best_params_\n",
        "params.update({\n",
        "    'objective': 'reg:squarederror',\n",
        "    'eval_metric': 'rmse',\n",
        "    'verbosity': 0,\n",
        "    'random_state': 42\n",
        "})\n",
        "\n",
        "# Siapkan list eval dan dictionary untuk menyimpan hasil\n",
        "evals = [(dtrain, 'train'), (dvalid, 'valid')]\n",
        "evals_result = {}\n",
        "\n",
        "# Train model dengan early stopping\n",
        "model = xgb.train(\n",
        "    params=params,\n",
        "    dtrain=dtrain,\n",
        "    num_boost_round=1000,\n",
        "    evals=evals,\n",
        "    early_stopping_rounds=20,\n",
        "    evals_result=evals_result,\n",
        "    verbose_eval=False\n",
        ")\n",
        "\n",
        "# Ambil dan konversi RMSE ke MSE\n",
        "rmse_train = np.array(evals_result['train']['rmse'])\n",
        "rmse_valid = np.array(evals_result['valid']['rmse'])\n",
        "mse_train = rmse_train ** 2\n",
        "mse_valid = rmse_valid ** 2\n",
        "\n",
        "# Visualisasi Learning Curve\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(mse_train, label='Train MSE')\n",
        "plt.plot(mse_valid, label='Validation MSE')\n",
        "plt.axvline(x=model.best_iteration, color='r', linestyle='--', label='Best Iteration')\n",
        "plt.title(\"XGBoost - MSE Learning Curve\")\n",
        "plt.xlabel(\"Boosting Rounds\")\n",
        "plt.ylabel(\"MSE\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhymMw9csX9N"
      },
      "outputs": [],
      "source": [
        "# Hitung RMSE di setiap boosting round\n",
        "rmse_train_curve = []\n",
        "rmse_valid_curve = []\n",
        "\n",
        "for i in range(1, model.best_iteration + 2):\n",
        "    y_pred_train_i = model.predict(dtrain, iteration_range=(0, i))\n",
        "    y_pred_valid_i = model.predict(dvalid, iteration_range=(0, i))\n",
        "    rmse_train_curve.append(np.sqrt(mean_squared_error(y_train, y_pred_train_i)))\n",
        "    rmse_valid_curve.append(np.sqrt(mean_squared_error(y_valid, y_pred_valid_i)))\n",
        "\n",
        "# Plot Learning Curve RMSE\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(rmse_train_curve, label='Train RMSE')\n",
        "plt.plot(rmse_valid_curve, label='Validation RMSE')\n",
        "plt.axvline(x=model.best_iteration, color='r', linestyle='--', label='Best Iteration')\n",
        "plt.title(\"XGBoost - RMSE Learning Curve\")\n",
        "plt.xlabel(\"Boosting Rounds\")\n",
        "plt.ylabel(\"RMSE\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kf331M6csBrJ"
      },
      "outputs": [],
      "source": [
        "# Hitung MAE di setiap boosting round\n",
        "mae_train = []\n",
        "mae_valid = []\n",
        "\n",
        "for i in range(1, model.best_iteration + 2):\n",
        "    y_pred_train_i = model.predict(dtrain, iteration_range=(0, i))\n",
        "    y_pred_valid_i = model.predict(dvalid, iteration_range=(0, i))\n",
        "    mae_train.append(mean_absolute_error(y_train, y_pred_train_i))\n",
        "    mae_valid.append(mean_absolute_error(y_valid, y_pred_valid_i))\n",
        "\n",
        "# Plot Learning Curve MAE\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(mae_train, label='Train MAE')\n",
        "plt.plot(mae_valid, label='Validation MAE')\n",
        "plt.axvline(x=model.best_iteration, color='r', linestyle='--', label='Best Iteration')\n",
        "plt.title(\"XGBoost - MAE Learning Curve\")\n",
        "plt.xlabel(\"Boosting Rounds\")\n",
        "plt.ylabel(\"MAE\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5B_hH1csCR9"
      },
      "outputs": [],
      "source": [
        "# Hitung R¬≤ di setiap boosting round\n",
        "r2_train = []\n",
        "r2_valid = []\n",
        "\n",
        "for i in range(1, model.best_iteration + 2):\n",
        "    y_pred_train_i = model.predict(dtrain, iteration_range=(0, i))\n",
        "    y_pred_valid_i = model.predict(dvalid, iteration_range=(0, i))\n",
        "    r2_train.append(r2_score(y_train, y_pred_train_i))\n",
        "    r2_valid.append(r2_score(y_valid, y_pred_valid_i))\n",
        "\n",
        "# Plot Learning Curve R¬≤\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(r2_train, label='Train R¬≤')\n",
        "plt.plot(r2_valid, label='Validation R¬≤')\n",
        "plt.axvline(x=model.best_iteration, color='r', linestyle='--', label='Best Iteration')\n",
        "plt.title(\"XGBoost - R¬≤ Learning Curve\")\n",
        "plt.xlabel(\"Boosting Rounds\")\n",
        "plt.ylabel(\"R¬≤ Score\")\n",
        "plt.legend()\n",
        "plt.grid(True, linestyle='--', alpha=0.5)\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gunakan kembali model hasil optimasi\n",
        "final_model_cv = xgb.XGBRegressor(**model_optimized.get_params())\n",
        "\n",
        "# Setup TimeSeriesSplit\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# List untuk menyimpan hasil setiap fold\n",
        "mse_list, rmse_list, mae_list, r2_list = [], [], [], []\n",
        "\n",
        "# Cross-validation manual\n",
        "for fold, (train_idx, test_idx) in enumerate(tscv.split(X_train)):\n",
        "    X_tr, X_val = X_train.iloc[train_idx], X_train.iloc[test_idx]\n",
        "    y_tr, y_val = y_train.iloc[train_idx], y_train.iloc[test_idx]\n",
        "\n",
        "    final_model_cv.fit(X_tr, y_tr)\n",
        "    y_pred = final_model_cv.predict(X_val)\n",
        "\n",
        "    mse = mean_squared_error(y_val, y_pred)\n",
        "    rmse = np.sqrt(mse)\n",
        "    mae = mean_absolute_error(y_val, y_pred)\n",
        "    r2 = r2_score(y_val, y_pred)\n",
        "\n",
        "    mse_list.append(mse)\n",
        "    rmse_list.append(rmse)\n",
        "    mae_list.append(mae)\n",
        "    r2_list.append(r2)\n",
        "\n",
        "    print(f\"Fold {fold+1}: MSE={mse:.4f}, RMSE={rmse:.4f}, MAE={mae:.4f}, R¬≤={r2:.4f}\")\n",
        "\n",
        "# Rata-rata hasil cross-validation\n",
        "print(\"\\n=== Rata-Rata Evaluasi Cross-Validation ===\")\n",
        "print(f\"Average MSE : {np.mean(mse_list):.4f}\")\n",
        "print(f\"Average RMSE: {np.mean(rmse_list):.4f}\")\n",
        "print(f\"Average MAE : {np.mean(mae_list):.4f}\")\n",
        "print(f\"Average R¬≤  : {np.mean(r2_list):.4f}\")"
      ],
      "metadata": {
        "id": "R_rLvG5DIblW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predictions\n",
        "model_baseline.fit(X_train, y_train)\n",
        "y_pred_test_baseline = model_baseline.predict(X_test)\n",
        "y_pred_test_bo = model_optimized.predict(X_test)\n",
        "\n",
        "# Model Evaluation\n",
        "models_metrics = {\n",
        "    'Baseline': {\n",
        "        'MSE': mean_squared_error(y_test, y_pred_test_baseline),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred_test_baseline)),\n",
        "        'MAE': mean_absolute_error(y_test, y_pred_test_baseline),\n",
        "        'R¬≤': r2_score(y_test, y_pred_test_baseline)\n",
        "    },\n",
        "    'BayesianOpt': {\n",
        "        'MSE': mean_squared_error(y_test, y_pred_test_bo),\n",
        "        'RMSE': np.sqrt(mean_squared_error(y_test, y_pred_test_bo)),\n",
        "        'MAE': mean_absolute_error(y_test, y_pred_test_bo),\n",
        "        'R¬≤': r2_score(y_test, y_pred_test_bo)\n",
        "    }\n",
        "}\n",
        "\n",
        "# Display comparison table\n",
        "metrics_df = pd.DataFrame({\n",
        "    'Metric': ['MSE', 'RMSE', 'MAE', 'R¬≤'],\n",
        "    'Baseline': [models_metrics['Baseline']['MSE'],\n",
        "                 models_metrics['Baseline']['RMSE'],\n",
        "                 models_metrics['Baseline']['MAE'],\n",
        "                 models_metrics['Baseline']['R¬≤']],\n",
        "    'BayesianOpt': [models_metrics['BayesianOpt']['MSE'],\n",
        "                    models_metrics['BayesianOpt']['RMSE'],\n",
        "                    models_metrics['BayesianOpt']['MAE'],\n",
        "                    models_metrics['BayesianOpt']['R¬≤']]\n",
        "}).round(4)\n",
        "\n",
        "print(\"\\n=== METRIC COMPARISON (Baseline vs Bayesian Optimization) ===\")\n",
        "print(metrics_df.to_string(index=False))\n",
        "\n",
        "# Calculate relative improvement percentage\n",
        "improvement_df = pd.DataFrame({\n",
        "    'Metric': ['MSE', 'RMSE', 'MAE', 'R¬≤'],\n",
        "    'BayesianOpt vs Baseline (%)': [\n",
        "        (models_metrics['Baseline']['MSE'] - models_metrics['BayesianOpt']['MSE']) / models_metrics['Baseline']['MSE'] * 100,\n",
        "        (models_metrics['Baseline']['RMSE'] - models_metrics['BayesianOpt']['RMSE']) / models_metrics['Baseline']['RMSE'] * 100,\n",
        "        (models_metrics['Baseline']['MAE'] - models_metrics['BayesianOpt']['MAE']) / models_metrics['Baseline']['MAE'] * 100,\n",
        "        (models_metrics['BayesianOpt']['R¬≤'] - models_metrics['Baseline']['R¬≤']) / abs(models_metrics['Baseline']['R¬≤']) * 100 if models_metrics['Baseline']['R¬≤'] != 0 else float('inf')\n",
        "    ]\n",
        "}).round(2)\n",
        "\n",
        "print(\"\\n=== RELATIVE IMPROVEMENT (BayesianOpt vs Baseline) ===\")\n",
        "print(improvement_df.to_string(index=False))"
      ],
      "metadata": {
        "id": "ZQiOyrAgm24a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Siapkan data test\n",
        "product_names_test = product_names.iloc[train_size + valid_size:].reset_index(drop=True)\n",
        "test_dates = created_times.iloc[train_size + valid_size:].reset_index(drop=True)\n",
        "\n",
        "# Transformasi balik dari log1p\n",
        "actual_sales = np.expm1(y_test)\n",
        "predicted_sales = np.expm1(y_pred_test_bo)\n",
        "\n",
        "# Buat DataFrame prediksi\n",
        "valid_len = len(y_test)\n",
        "prediction_df = pd.DataFrame({\n",
        "    'Product_Name': product_names_test[-valid_len:].reset_index(drop=True),\n",
        "    'Tanggal': pd.to_datetime(test_dates[-valid_len:]).reset_index(drop=True),\n",
        "    'Actual_Sales': actual_sales.values,\n",
        "    'Predicted_Sales': predicted_sales\n",
        "})\n",
        "\n",
        "# Ambil 1 produk terlaris dari test set\n",
        "top_product = prediction_df['Product_Name'].value_counts().idxmax()\n",
        "\n",
        "# Agregasi data asli per bulan\n",
        "product_idx = product_names == top_product\n",
        "produk_full = pd.DataFrame({\n",
        "    'Product_Name': [top_product] * sum(product_idx),\n",
        "    'Created_Time': pd.to_datetime(created_times[product_idx].reset_index(drop=True)),\n",
        "    'Quantity': df.loc[product_idx, target_column].reset_index(drop=True)\n",
        "})\n",
        "\n",
        "produk_full['year_month'] = produk_full['Created_Time'].dt.to_period('M')\n",
        "produk_actual_agg = produk_full.groupby('year_month')['Quantity'].sum().reset_index()\n",
        "produk_actual_agg.rename(columns={'Quantity': 'Actual_Sales_Full'}, inplace=True)\n",
        "\n",
        "# Agregasi data prediksi test\n",
        "produk_pred_raw = prediction_df[prediction_df['Product_Name'] == top_product].copy()\n",
        "produk_pred_raw['year_month'] = produk_pred_raw['Tanggal'].dt.to_period('M')\n",
        "\n",
        "produk_pred_agg = produk_pred_raw.groupby('year_month').agg({\n",
        "    'Actual_Sales': 'sum',\n",
        "    'Predicted_Sales': 'sum'\n",
        "}).reset_index()\n",
        "\n",
        "# Gabungkan data\n",
        "produk_actual_agg['year_month_str'] = produk_actual_agg['year_month'].astype(str)\n",
        "produk_pred_agg['year_month_str'] = produk_pred_agg['year_month'].astype(str)\n",
        "\n",
        "produk_combined = pd.merge(\n",
        "    produk_actual_agg,\n",
        "    produk_pred_agg,\n",
        "    on='year_month_str',\n",
        "    how='outer'\n",
        ")\n",
        "\n",
        "produk_combined['year_month'] = produk_combined['year_month_x'].fillna(produk_combined['year_month_y'])\n",
        "produk_combined = produk_combined.sort_values('year_month')\n",
        "\n",
        "# Visualisasi perbandingan prediksi dengan aktual\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "valid_full = ~produk_combined['Actual_Sales_Full'].isna()\n",
        "plt.plot(produk_combined.loc[valid_full, 'year_month'].dt.to_timestamp(),\n",
        "         produk_combined.loc[valid_full, 'Actual_Sales_Full'],\n",
        "         label='Aktual (Sejak Awal)', marker='o', color='blue')\n",
        "\n",
        "valid_test = ~produk_combined['Actual_Sales'].isna()\n",
        "plt.plot(produk_combined.loc[valid_test, 'year_month'].dt.to_timestamp(),\n",
        "         produk_combined.loc[valid_test, 'Actual_Sales'],\n",
        "         label='Aktual (Test)', marker='s', color='green')\n",
        "\n",
        "valid_pred = ~produk_combined['Predicted_Sales'].isna()\n",
        "plt.plot(produk_combined.loc[valid_pred, 'year_month'].dt.to_timestamp(),\n",
        "         produk_combined.loc[valid_pred, 'Predicted_Sales'],\n",
        "         label='Prediksi', linestyle='--', marker='x', color='orange')\n",
        "\n",
        "min_test_date = produk_combined.loc[valid_test, 'year_month'].min()\n",
        "if not pd.isna(min_test_date):\n",
        "    plt.axvline(x=min_test_date.to_timestamp(), color='gray', linestyle='--', alpha=0.7)\n",
        "    plt.text(min_test_date.to_timestamp(), plt.ylim()[1]*0.95, 'Awal Test', rotation=90, verticalalignment='top')\n",
        "\n",
        "plt.margins(x=0.05)\n",
        "plt.xlabel('Bulan', fontsize=12)\n",
        "plt.ylabel('Jumlah Penjualan', fontsize=12)\n",
        "plt.title(f'Prediksi vs Aktual Penjualan Produk: {top_product}', fontsize=14)\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "\n",
        "# Tambahkan metrik evaluasi\n",
        "if valid_test.any() and valid_pred.any():\n",
        "    test_values = produk_combined.loc[valid_test, 'Actual_Sales']\n",
        "    pred_values = produk_combined.loc[valid_test, 'Predicted_Sales']\n",
        "    common_idx = test_values.index.intersection(pred_values.index)\n",
        "\n",
        "    if len(common_idx) > 0:\n",
        "        test_values = test_values.loc[common_idx]\n",
        "        pred_values = pred_values.loc[common_idx]\n",
        "\n",
        "        mape = np.mean(np.abs((test_values - pred_values) / test_values)) * 100\n",
        "        rmse = np.sqrt(np.mean((test_values - pred_values) ** 2))\n",
        "\n",
        "        plt.figtext(0.15, 0.02, f'MAPE: {mape:.2f}%', fontsize=10)\n",
        "        plt.figtext(0.32, 0.02, f'RMSE: {rmse:.2f}', fontsize=10)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Cetak diagnostik\n",
        "print(f\"Jumlah bulan dalam data penuh: {len(produk_actual_agg)}\")\n",
        "print(f\"Jumlah bulan dalam data test: {len(produk_pred_agg)}\")\n",
        "print(f\"Jumlah transaksi dalam data test untuk produk ini: {len(produk_pred_raw)}\")\n",
        "print(\"\\nPola Bulanan:\")\n",
        "combined_months = produk_combined[['year_month', 'Actual_Sales_Full', 'Actual_Sales', 'Predicted_Sales']]\n",
        "print(combined_months.to_string(index=False))"
      ],
      "metadata": {
        "id": "4ucJoo-XtEJA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prediksi bulan depan\n",
        "last_date = created_times.iloc[train_size + valid_size + len(X_test) - 1]\n",
        "product_name = product_names.iloc[train_size + valid_size + len(X_test) - 1]\n",
        "\n",
        "next_month_period = (pd.to_datetime(last_date) + pd.DateOffset(months=1)).to_period(\"M\")\n",
        "next_month = next_month_period.to_timestamp()\n",
        "\n",
        "test_dates = created_times.iloc[train_size + valid_size : train_size + valid_size + len(X_test)]\n",
        "\n",
        "# Filter test data untuk bulan saat ini\n",
        "current_month_period = pd.to_datetime(last_date).to_period(\"M\")\n",
        "mask_current_month = test_dates.dt.to_period(\"M\") == current_month_period\n",
        "X_current_month = X_test[mask_current_month]\n",
        "\n",
        "if X_current_month.empty:\n",
        "    X_current_month = X_test\n",
        "    current_month_avg_daily = np.expm1(y_test).mean()\n",
        "else:\n",
        "    y_pred_log_current = model_optimized.predict(X_current_month)\n",
        "    current_month_avg_daily = np.expm1(y_pred_log_current).mean()\n",
        "\n",
        "# Dapatkan data penjualan bulanan historis\n",
        "actual_test_df = pd.DataFrame({\n",
        "    'Date': test_dates.reset_index(drop=True),\n",
        "    'Sales': np.expm1(y_test).values,\n",
        "    'Product_Name': product_names.iloc[train_size + valid_size : train_size + valid_size + len(X_test)].values\n",
        "})\n",
        "actual_test_df = actual_test_df[actual_test_df['Product_Name'] == product_name]\n",
        "actual_test_df['year_month'] = actual_test_df['Date'].dt.to_period('M')\n",
        "monthly_actual = actual_test_df.groupby('year_month')['Sales'].sum().reset_index()\n",
        "monthly_actual['year_month'] = monthly_actual['year_month'].dt.to_timestamp()\n",
        "\n",
        "# Analisis tren historis untuk faktor musiman\n",
        "if len(monthly_actual) >= 3:\n",
        "    last_3_months = monthly_actual.tail(3)\n",
        "    monthly_sales = last_3_months['Sales'].values\n",
        "\n",
        "    growth_rates = [monthly_sales[i] / monthly_sales[i-1] for i in range(1, len(monthly_sales)) if monthly_sales[i-1] > 0]\n",
        "    seasonal_factor = np.mean(growth_rates) if growth_rates else 1.0\n",
        "    seasonal_factor = max(0.7, min(seasonal_factor, 1.3))\n",
        "elif len(monthly_actual) == 2:\n",
        "    growth_rate = monthly_actual['Sales'].iloc[1] / monthly_actual['Sales'].iloc[0] if monthly_actual['Sales'].iloc[0] > 0 else 1.0\n",
        "    seasonal_factor = max(0.7, min(growth_rate, 1.3))\n",
        "else:\n",
        "    seasonal_factor = 1.0\n",
        "\n",
        "# Hitung prediksi untuk bulan depan\n",
        "if not monthly_actual.empty:\n",
        "    last_month_total = monthly_actual['Sales'].iloc[-1]\n",
        "    days_in_next_month = pd.Period(next_month_period).days_in_month\n",
        "    days_in_current_month = pd.Period(current_month_period).days_in_month\n",
        "    days_ratio = days_in_next_month / days_in_current_month\n",
        "    next_month_pred_total = last_month_total * seasonal_factor * days_ratio\n",
        "else:\n",
        "    days_in_next_month = pd.Period(next_month_period).days_in_month\n",
        "    next_month_pred_total = current_month_avg_daily * days_in_next_month\n",
        "\n",
        "# Pastikan prediksi masuk akal\n",
        "if not monthly_actual.empty:\n",
        "    min_reasonable = last_month_total * 0.7\n",
        "    max_reasonable = last_month_total * 1.5\n",
        "    next_month_pred_total = max(min_reasonable, min(next_month_pred_total, max_reasonable))\n",
        "\n",
        "# Hitung interval kepercayaan\n",
        "if len(monthly_actual) >= 3:\n",
        "    historical_std = monthly_actual['Sales'].std()\n",
        "    y_pred_test_opt = model_optimized.predict(X_test)\n",
        "    rmse_test_opt = np.sqrt(mean_squared_error(y_test, y_pred_test_opt))\n",
        "    prediction_std = (rmse_test_opt + historical_std * 0.5) * seasonal_factor\n",
        "else:\n",
        "    prediction_std = rmse_test_opt * np.sqrt(days_in_next_month) * seasonal_factor\n",
        "\n",
        "ci_lower = max(0, next_month_pred_total - prediction_std * 2)\n",
        "ci_upper = next_month_pred_total + prediction_std * 2\n",
        "\n",
        "# Tampilkan hasil prediksi\n",
        "print(f\"\\nPrediction for {next_month_period.strftime('%B %Y')} with {days_in_next_month} days.\")\n",
        "print(f\"Predicted total sales: {next_month_pred_total:.2f} units\")\n",
        "print(f\"Confidence interval: {ci_lower:.2f} - {ci_upper:.2f}\")\n",
        "\n",
        "# Visualisasi prediksi bulan depan\n",
        "plt.figure(figsize=(12, 6))\n",
        "\n",
        "plt.plot(monthly_actual['year_month'], monthly_actual['Sales'], 'b-', label='Actual Sales (Per Month)', linewidth=2)\n",
        "plt.plot([monthly_actual['year_month'].iloc[-1], next_month],\n",
        "         [monthly_actual['Sales'].iloc[-1], next_month_pred_total],\n",
        "         'r--', label='Prediction', linewidth=2)\n",
        "plt.scatter(next_month, next_month_pred_total, color='red', s=100, label='Prediksi Bulan Depan')\n",
        "plt.fill_between([next_month], [ci_lower], [ci_upper], color='red', alpha=0.3, label='Confidence Interval')\n",
        "\n",
        "plt.annotate(f\"{next_month_pred_total:.2f}\",\n",
        "             (next_month, next_month_pred_total),\n",
        "             textcoords=\"offset points\", xytext=(0, 10), ha='center', fontsize=12, color='red')\n",
        "\n",
        "plt.title(f'Next Month Sales Prediction for {product_name}', fontsize=14)\n",
        "plt.xlabel('Month')\n",
        "plt.ylabel('Sales Quantity')\n",
        "plt.xticks(rotation=45)\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.legend(loc='best')\n",
        "plt.tight_layout()\n",
        "\n",
        "y_min = max(0, min(ci_lower, min(monthly_actual['Sales'])) * 0.8)\n",
        "y_max = max(ci_upper, max(monthly_actual['Sales'])) * 1.2\n",
        "plt.ylim(y_min, y_max)\n",
        "\n",
        "plt.savefig(f'next_month_prediction_{product_name}.png', dpi=300)\n",
        "plt.show()\n",
        "\n",
        "# Simpan laporan\n",
        "with open(f'prediction_summary_{product_name}.txt', 'a') as f:\n",
        "    f.write(\"\\nNEXT MONTH SALES PREDICTION\\n\")\n",
        "    f.write(f\"- Predicted month: {next_month.strftime('%Y-%m')}\\n\")\n",
        "    f.write(f\"- Predicted sales: {next_month_pred_total:.2f}\\n\")\n",
        "    f.write(f\"- Confidence Interval: {ci_lower:.2f} to {ci_upper:.2f}\\n\")\n",
        "    f.write(f\"- Historical growth factor: {seasonal_factor:.2f}\\n\")\n",
        "    f.write(f\"- Days in month adjustment: {days_ratio:.2f}\\n\")\n",
        "\n",
        "print(f\"‚úÖ Chart saved: next_month_prediction_{product_name}.png\")\n",
        "print(f\"üìù Summary added to: prediction_summary_{product_name}.txt\")"
      ],
      "metadata": {
        "id": "f7CfylqttL1A"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}